{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survwrap import CoxNet, CoxPH\n",
    "from survwrap import load_test_data, get_time, get_indicator\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_test_data('veterans_lung_cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X, y = load_test_data()\n",
    "min(get_time(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343065693430657"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(get_indicator(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CoxNet(alpha=0.01).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7380736029077692"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7150570062526584"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(cross_val_score(m, X, y, cv=KFold(10, shuffle=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from survwrap import get_time, get_indicator\n",
    "\n",
    "def make_survival_scorer(\n",
    "    score_func, needs=\"failure\", classification=False, aggregate='mean', time_mode=\"events\", time_values=None, **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a time-dependent survival scoring function for survival analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - score_func (callable, with signature (y_pred, y_true)): A function that computes a score based on predicted and true values.\n",
    "    - needs (str, optional): The type of predictions needed. Either \"failure\" or \"survival\" probability predictions. Default is \"failure\".\n",
    "    - classification (bool, optional): If True, treat score_func as a classification score and run it on positive/negative events computed separately for each time point. Default is False.\n",
    "    - aggregate (str, optional): The method to aggregate scores over different time points. Options include 'mean', 'median', 'sum', or 'no' for no aggregation. Default is 'mean'.\n",
    "    - time_mode (str, optional): The mode for specifying prediction times. Options are \"events\" (using event times), \"quantiles\" (using quantiles of event times), or \"absolute\" (using specified absolute time values). Default is \"events\".\n",
    "    - time_values (array-like or float, optional): The time values depending on the chosen time_mode. If time_mode is \"events\", time_values should be None. If time_mode is \"quantiles\", time_values should be an array of quantiles between 0 and 1. If time_mode is \"absolute\", time_values should be an array-like object or a float representing absolute time values.\n",
    "    - **kwargs: Additional keyword arguments to be passed to the underlying score_func.\n",
    "\n",
    "    Returns:\n",
    "    - scorer (callable with signature (estimator, X, y)): A time-dependent scoring function that computes score_func at different time points and aggregate the results.\n",
    "      \n",
    "    Notes:\n",
    "      that can be used \n",
    "\n",
    "    Notes:\n",
    "    - The resulting scorer can be used as a standard scikit-learn scorer with survival outcomes and survwrap models. See the example\n",
    "\n",
    "    ```\n",
    "    from survwrap import CoxNet, load_test_data\n",
    "    from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "    roc_auc_at_quartiles = make_survival_scorer(roc_auc_score, classification=True, time_mode='quantiles', time_values=[0.25, 0.5, 0.75])\n",
    "    brier_at_quartiles = make_survival_scorer(lambda *args: -brier_score_loss(*args), classification=True, time_mode='quantiles', time_values=[0.25, 0.5, 0.75]),\n",
    "\n",
    "    X, y = load_test_data('veterans_lung_cancer')\n",
    "\n",
    "    cross_val_score(CoxNet(), X, y, scoring=roc_auc_at_quartiles)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def scorer(estimator, X, y):\n",
    "        event_times = get_time(y)[get_indicator(y)]\n",
    "\n",
    "        # get evaluation times\n",
    "        if time_mode == \"events\":\n",
    "            pred_times = event_times\n",
    "        elif time_mode == \"quantiles\":\n",
    "            pred_times = numpy.quantile(event_times, time_values)\n",
    "        elif time_mode == \"absolute\":\n",
    "            pred_times = time_values\n",
    "        else:  # keep as is, must be a scalar or sequence\n",
    "            raise ValueError('needs must be either \"events\", \"quantiles\" or \"absolute\"')\n",
    "        \n",
    "        # compute predictions at pred_times\n",
    "        if needs == \"failure\":\n",
    "            y_pred = 1.0 - estimator.predict_survival(X, pred_times)\n",
    "        elif needs == \"survival\":\n",
    "            y_pred = estimator.predict_survival(X, pred_times)\n",
    "        else:\n",
    "            raise ValueError('needs must be either \"failure\" or \"survival\"')\n",
    "        \n",
    "        # run score_func at each time\n",
    "        scores = []\n",
    "        for p, t in zip(y_pred.T, pred_times):\n",
    "            if classification:\n",
    "                y_time = get_time(y)\n",
    "                y_ind = get_indicator(y)\n",
    "\n",
    "                informative = (y_time > t) | y_ind\n",
    "                positive = (y_time <= t) & y_ind\n",
    "\n",
    "                score = score_func(positive[informative], p[informative])\n",
    "            else:\n",
    "                score = score_func(y, p)\n",
    "            if score != score:\n",
    "                print(f'bad survival score at time {t} computed by {score_func}')\n",
    "            scores.append(score)\n",
    "\n",
    "        # aggregate scores for different times\n",
    "        if aggregate == 'no':\n",
    "            return numpy.array(scores)\n",
    "        else:\n",
    "            if hasattr(numpy, aggregate):\n",
    "                return getattr(numpy, aggregate)(scores)\n",
    "            else:\n",
    "                raise ValueError(f'unknonw aggregate value `{aggregate}`')\n",
    "\n",
    "    scorer.__name__ = score_func.__name__ + '_td_scorer'\n",
    "\n",
    "    return scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60286195, 0.8446712 , 0.58463913, 0.76368807, 0.80531136])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from survwrap import CoxNet, load_test_data\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from sklearn.model_selection import cross_val_score\n",
    "roc_auc_at_quartiles = make_survival_scorer(roc_auc_score, classification=True, time_mode='quantiles', time_values=[0.25, 0.5, 0.75])\n",
    "brier_at_quartiles = make_survival_scorer(lambda *args: -brier_score_loss(*args), classification=True, time_mode='quantiles', time_values=[0.25, 0.5, 0.75]),\n",
    "\n",
    "X, y = load_test_data('veterans_lung_cancer')\n",
    "\n",
    "cross_val_score(CoxNet(), X, y, scoring=roc_auc_at_quartiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survwrap import *\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "qt = dict(time_mode='quantiles', time_values=numpy.linspace(0, 1, 5)[1:-1])\n",
    "scorers = {\n",
    "    'antolini': concordance_index_antolini_scorer,\n",
    "    'c-index-qt': make_survival_scorer(concordance_index_score, classification=False, **qt),\n",
    "    'new-roc-auc': make_survival_scorer(roc_auc_score, classification=True, **qt),\n",
    "    #'new-roc-auc-bad': make_survival_scorer(roc_auc_score, classification=False, **qt),\n",
    "    'old-roc-auc': make_time_dependent_scorer(roc_auc_td_score, aggregate=None, **qt),\n",
    "    'new-brier': make_survival_scorer(lambda *args: -brier_score_loss(*args), classification=True, **qt),\n",
    "    #'new-brier-bad': make_survival_scorer(lambda *args: -brier_score_loss(*args), classification=False, **qt),\n",
    "    'old-brier': make_time_dependent_scorer(neg_brier_score, aggregate=None, **qt),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antolini</th>\n",
       "      <th>c-index-qt</th>\n",
       "      <th>new-roc-auc</th>\n",
       "      <th>old-roc-auc</th>\n",
       "      <th>new-brier</th>\n",
       "      <th>old-brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antolini</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.904753</td>\n",
       "      <td>0.892707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c-index-qt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.904753</td>\n",
       "      <td>0.892707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new-roc-auc</th>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912507</td>\n",
       "      <td>0.900834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old-roc-auc</th>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912507</td>\n",
       "      <td>0.900834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new-brier</th>\n",
       "      <td>0.904753</td>\n",
       "      <td>0.904753</td>\n",
       "      <td>0.912507</td>\n",
       "      <td>0.912507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old-brier</th>\n",
       "      <td>0.892707</td>\n",
       "      <td>0.892707</td>\n",
       "      <td>0.900834</td>\n",
       "      <td>0.900834</td>\n",
       "      <td>0.999499</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             antolini  c-index-qt  new-roc-auc  old-roc-auc  new-brier  \\\n",
       "antolini     1.000000    1.000000     0.994664     0.994664   0.904753   \n",
       "c-index-qt   1.000000    1.000000     0.994664     0.994664   0.904753   \n",
       "new-roc-auc  0.994664    0.994664     1.000000     1.000000   0.912507   \n",
       "old-roc-auc  0.994664    0.994664     1.000000     1.000000   0.912507   \n",
       "new-brier    0.904753    0.904753     0.912507     0.912507   1.000000   \n",
       "old-brier    0.892707    0.892707     0.900834     0.900834   0.999499   \n",
       "\n",
       "             old-brier  \n",
       "antolini      0.892707  \n",
       "c-index-qt    0.892707  \n",
       "new-roc-auc   0.900834  \n",
       "old-roc-auc   0.900834  \n",
       "new-brier     0.999499  \n",
       "old-brier     1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame({\n",
    "    score_name: cross_val_score(CoxNet(), X, y, scoring=score_func, error_score='raise')\n",
    "    for score_name, score_func in scorers.items()\n",
    "}).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_scores(scores, mode='mean'):\n",
    "    if mode == 'no':\n",
    "        return scores\n",
    "    else:\n",
    "        if hasattr(numpy, mode):\n",
    "            return getattr(numpy, mode)(scores)\n",
    "        else:\n",
    "            raise ValueError(f'unknonw aggregate value `{mode}`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_survival_from_classification_score(score_func):\n",
    "    def td_score(y_true, y_pred, times, **kwargs):\n",
    "        assert len(y_pred.shape) == 1, f'vector expected for y_pred, found an array of shape {y_pred.shape} '\n",
    "        y_time = get_time(y_true)\n",
    "        y_ind = get_indicator(y_true)\n",
    "\n",
    "        informative = (y_time > times) | y_ind\n",
    "        positive = (y_time <= times) & y_ind\n",
    "\n",
    "        return score_func(positive[informative], y_pred[informative], **kwargs)\n",
    "\n",
    "    return td_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers = {\n",
    "    'concordance-index-antolini': concordance_index_antolini_scorer,\n",
    "    'roc-auc-quartiles': make_time_dependent_scorer(roc_auc_td_score, time_mode='quantiles', time_values=numpy.linspace(0, 1, 5)[1:-1]),\n",
    "    'neg-brier-quartiles': make_time_dependent_scorer(neg_brier_score, time_mode='quantiles', time_values=numpy.linspace(0, 1, 5)[1:-1], aggregate=None),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_dependent_classification_score(score_func, aggregate=\"mean\"):\n",
    "    \"\"\"Make a time-dependent survival metric from a classification metric.\n",
    "\n",
    "    Given a time threshold t, a survival outcome can be reduced to a classification\n",
    "    outcome by taking as positives all events occurring before t and as negatives\n",
    "    all events or censorings occurring after t (censorings before t are discarded\n",
    "    as non informative).  Using this reduction at multiple times we can extend any\n",
    "    classification metric to survival.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    score_func : callable\n",
    "        Classification metric function with signature\n",
    "        ``score_func(y_true, y_pred, **kwargs)\n",
    "\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    scorer: callable with signature (y_true, y_pred, times, **kwargs)\n",
    "    \"\"\"\n",
    "\n",
    "    def td_score(y_true, y_pred, times, **kwargs):\n",
    "        y_time = get_time(y_true)\n",
    "        y_ind = get_indicator(y_true)\n",
    "        if len(y_pred.shape) == 2:\n",
    "            y_time = y_time.reshape((-1, 1))\n",
    "            y_ind = y_ind.reshape((-1, 1))\n",
    "\n",
    "        informative = (y_time > times) | y_ind\n",
    "        positive = (y_time <= times) & y_ind\n",
    "\n",
    "        if len(y_pred.shape) == 2:\n",
    "            scores = numpy.array(\n",
    "                [\n",
    "                    score_func(positive[mask, i], y_pred[mask, i], **kwargs)\n",
    "                    for i, mask in enumerate(informative.T)\n",
    "                ]\n",
    "            )\n",
    "            if aggregate == \"no\":\n",
    "                return scores\n",
    "            elif aggregate == \"mean\":\n",
    "                return numpy.mean(scores)\n",
    "        else:\n",
    "            return score_func(positive[informative], y_pred[informative], **kwargs)\n",
    "\n",
    "    return td_score\n",
    "\n",
    "\n",
    "def make_time_dependent_scorer(\n",
    "    score_func, needs=\"failure\", aggregate='mean', time_mode=\"events\", time_values=None, **kwargs\n",
    "):\n",
    "    \"\"\"Make a scorer from a time-dependent survival metric function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    score_func: callable\n",
    "        Time-dependent score or loss function with signature\n",
    "        ``score_func(y_true, y_pred, times, **kwargs)\n",
    "    needs: string\n",
    "        the type of survival prediction needed for td_score, one of\n",
    "        `failure`: probability of event before a given time,\n",
    "        `survival`: probability of event after a given time.\n",
    "    times: string or sequence\n",
    "        indicates at which times to evaluate td_score\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    scorer: callable with signature (estimator, X, y)\n",
    "    \"\"\"\n",
    "\n",
    "    def scorer(estimator, X, y):\n",
    "        event_times = get_time(y)[get_indicator(y)]\n",
    "\n",
    "        if time_mode == \"events\":\n",
    "            pred_times = event_times\n",
    "        elif time_mode == \"quantiles\":\n",
    "            pred_times = numpy.quantile(event_times, time_values)\n",
    "        elif time_mode == \"absolute\":\n",
    "            pred_times = time_values\n",
    "        else:  # keep as is, must be a scalar or sequence\n",
    "            raise ValueError('needs must be either \"events\", \"quantiles\" or \"absolute\"')\n",
    "\n",
    "        if needs == \"failure\":\n",
    "            y_pred = 1.0 - estimator.predict_survival(X, pred_times)\n",
    "        elif needs == \"survival\":\n",
    "            y_pred = estimator.predict_survival(X, pred_times)\n",
    "        else:\n",
    "            raise ValueError('needs must be either \"failure\" or \"survival\"')\n",
    "\n",
    "        #assert y_pred.shape[]\n",
    "        # FIXME aggregate is also defined in make_td_score, maybe it is redundant?\n",
    "        if aggregate is None: # score_func handles multiple times by itself\n",
    "            return score_func(y, y_pred, pred_times, **kwargs)\n",
    "        elif aggregate == 'mean':\n",
    "            scores = numpy.array([\n",
    "                score_func(y, p)\n",
    "                for p in y_pred.T\n",
    "            ])\n",
    "            return numpy.mean(scores)\n",
    "    scorer.__name__ = score_func.__name__ + '_td_scorer'\n",
    "\n",
    "    return scorer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
