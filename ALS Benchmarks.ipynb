{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b51233-419d-4bfb-b931-ab2070616fa4",
   "metadata": {},
   "source": [
    "# Deep learning survival methods benchmarks on ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbd484-3392-41df-bede-10424b01cc65",
   "metadata": {},
   "source": [
    "In questo notebook vorrei raccogliere tutti i benchmark che abbiamo fatto Corrado ed io e uniformarli\n",
    "- per semplificare usiamo solo dataset staticizzati, tanto non ci sono un'enormita' di feature dinamiche per la maggior parte dei pazienti\n",
    "- mi piacerebbe investigare se il modo di trattare gli eventi (indipendenti, competing, multi-state) ha impatto sulla predizione\n",
    "- stiamo attenti al brier score e ai metodi che usano ipcw perche' in questo dataset mi pare faccia un casino per tempi bassi\n",
    "- bisogna decidere una singola metrica per ottimizzare i modelli, anche se poi ne calcoliamo varie\n",
    "- i tempi di valutazione li prendiamo come quantili dei tempi degli eventi globali? o dal dataset di train?\n",
    "\n",
    "- survtrace: sembra che ci sia un trattamento particolare per le feature categoriche, al momento gliele passiamo OHE come numeriche, forse non e' la cosa migliore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54472810-003f-49d5-ad9e-d6b580c1cbc1",
   "metadata": {},
   "source": [
    "### Cose da fare\n",
    "- provare ad aggiungere soden?\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec7c593-1877-4e5e-8e12-ad1ca48b8c59",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "Staticized datasets at first ALSFRS and after six months\n",
    "\n",
    "There are three events: NIV, PEG and death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814a72d7-fd95-4952-91e3-b6ab4e53ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5174aa-589e-43a4-bd9b-549179eea87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert Xdiag.index.equals(event_df.index)\n",
    "#Ydiag = {\n",
    "#    e: numpy.array(\n",
    "#        event_df[[e + '_event', e + '_time']].apply(tuple, axis=1), \n",
    "#        dtype=[('event', bool), ('time', float)]\n",
    "#    ) for e in ['death', 'NIV', 'PEG']\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03dfbf8d-5e76-4fc1-a58b-1a963c22fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y6m = numpy.array(\n",
    "#    pandas.read_csv('death6_Y.csv', index_col='id').apply(tuple, axis=1),\n",
    "#    dtype=[('event', bool), ('time', float)]\n",
    "#)\n",
    "#Y6m['time'] -= 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a5ce6-e99b-456b-af34-42e957a09a55",
   "metadata": {},
   "source": [
    "### Train-test split and final preprocessing before prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f960a6b3-6fa5-4683-8cd6-e9736e14633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba7e825-da35-4a48-95a8-f9646fd97f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(*args):\n",
    "    return (a.values if hasattr(a, 'values') else a for a in args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071267bc-4bdb-44ad-8491-34a8349474d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_for_prediction(X, time, event, max_miss=0.3, seed=0):\n",
    "    Xclean = X[:, numpy.isnan(X).mean(axis=0) < max_miss]\n",
    "    # shift times to make them positive\n",
    "    if numpy.min(time) == 0:\n",
    "        time = time.copy()\n",
    "        time += numpy.min(time[time > 0])/3\n",
    "        \n",
    "    X_train, X_test, time_train, time_test, event_train, event_test = train_test_split(Xclean, time, event, test_size=0.2, random_state=seed)\n",
    "    assert all(numpy.nanstd(X_train, axis=0) > 0)\n",
    "    scaler  = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    imputer = SimpleImputer(strategy='median').fit(X_train)\n",
    "    X_train = imputer.transform(X_train)\n",
    "    X_test  = imputer.transform(X_test)\n",
    "    return dict(train=(X_train, time_train, event_train), test=(X_test, time_test, event_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2300795d-acf1-4d21-a0cd-7577b37f5720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surv_vector(times, events):\n",
    "    assert times.shape == events.shape\n",
    "    return numpy.array(\n",
    "        list(zip(*to_numpy(events, times))), \n",
    "        dtype=[('event', bool), ('time', float)]\n",
    "    )\n",
    "def surv_matrices(times, events):\n",
    "    assert times.shape == events.shape\n",
    "    times, events = to_numpy(times, events)\n",
    "    return [\n",
    "        surv_vector(times[:, evt], events[:, evt])\n",
    "        for evt in range(times.shape[1])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9461723-b8c1-4036-8822-f3f494502749",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Encapsulate each different method into a class that generate the model from an Optuna trial object and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36bf80b5-a61c-4157-9976-85bd7d30828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    class SurvMethod:\n",
    "        def __init__(self, trial):\n",
    "            self.trial = trial\n",
    "            self.model_params = trial2model_params(trial)\n",
    "            self.fit_params = {}\n",
    "        @staticmethod\n",
    "        def trial2model_params(trial):\n",
    "            raise NotImplemented()\n",
    "        @staticmethod\n",
    "        def trial2fit_params(trial):\n",
    "            return {}\n",
    "        def train(self, X, Y):\n",
    "            self.model = self.trial2model(self.trial)\n",
    "            self.model.fit(X, y, **trial2fit_params(self.trial))\n",
    "        def predict(self, X):\n",
    "            self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0a150f-b39e-4835-9527-f1c595388968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def hash_dict(d):\n",
    "    return json.dumps(dict(sorted(d.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "510250bd-6a27-44a1-8d97-bff2ba81b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "def my_open(path, mode):\n",
    "    return (gzip.open if path.endswith('.gz') else open)(path, mode)\n",
    "\n",
    "def load_from(path):\n",
    "    with my_open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def dump_to(obj, path):\n",
    "    with my_open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_or_new(func, path):\n",
    "    try:\n",
    "        return load_from(path)\n",
    "    except FileNotFoundError:\n",
    "        return func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217e9455-c221-4074-af72-ee067b9d35ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_as_bool(event):\n",
    "    return event if event.dtype == 'bool' else event == 1\n",
    "def get_time_quantiles(*y, q):\n",
    "    if len(y) == 2:\n",
    "        time, event = y\n",
    "        event = event_as_bool(event)\n",
    "        if len(time.shape) == 1:\n",
    "            return numpy.quantile(time[event], q)\n",
    "        return numpy.array([numpy.quantile(time[:,evt][event[:,evt]], q) for evt in range(time.shape[1])])\n",
    "    elif len(y) == 1:\n",
    "        y, = y\n",
    "        return numpy.quantile(y['time'][y['event']], q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da5782e8-634a-4ffb-b8db-59edb94a6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_brier(y, preds, t):\n",
    "    keep = (y['time'] > t) | y['event']\n",
    "    y_bin = y['time'][keep] <= t\n",
    "    return numpy.mean(numpy.square(preds[keep] - y_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a412df5-1c80-4815-9486-9841f4806bfc",
   "metadata": {},
   "source": [
    "## Cross-validation and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed512218-880c-40f9-ae8e-16fa94f14861",
   "metadata": {},
   "source": [
    "Evaluate method in cross-validation, return average c-index across cross-validation set, event and evaluation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d2bbb1f-f5a5-40c3-ad32-f3550e8eb50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FailedModel(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "732e807e-fb6d-41d9-9b66-fcc74aa1a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_probs(model, p):\n",
    "    nans = numpy.sum(numpy.isnan(p))\n",
    "    if nans:\n",
    "        raise FailedModel(f'{model.short_name} model bad prediction: found {nans} nans')\n",
    "    unders = numpy.sum(p < 0.0)\n",
    "    if unders:\n",
    "        raise FailedModel(f'{model.short_name} model bad prediction: found {unders} values greater than 1.0')\n",
    "    overs = numpy.sum(p > 1.0)\n",
    "    if overs:\n",
    "        raise FailedModel(f'{model.short_name} model bad prediction: found {overs} values greater than 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "682e7303-c88d-4ee3-8067-acf8b884abee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefinition to handle competing events where the event is expressed as an integer\n",
    "# 0 is censoring, 1 is the main event and values greater than 1 are other competing events that we treat as censoring when testing performance\n",
    "def concordance_index_censored(event, time, preds):\n",
    "    from sksurv.metrics import concordance_index_censored as cic\n",
    "    return cic(event == 1, time, preds)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a74a5de6-43fe-4958-9dc0-e6cbf106862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Silence:\n",
    "    def __enter__(self, stdout=True, stderr=True):\n",
    "        null_output = open('/dev/null', 'wt')\n",
    "        if stdout:\n",
    "            self.original_stdout = sys.stdout\n",
    "            sys.stdout = null_output\n",
    "        else:\n",
    "            self.original_stdout = None\n",
    "        if stderr:\n",
    "            self.original_stderr = sys.stderr\n",
    "            sys.stderr = null_output\n",
    "        else:\n",
    "            self.original_stderr = None\n",
    "            \n",
    "        sys.stdout\n",
    "    def __exit__(self, *_):\n",
    "        if self.original_stdout is not None:\n",
    "            sys.stdout = self.original_stdout\n",
    "        if self.original_stderr is not None:\n",
    "            sys.stdout = self.original_stderr\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e78ae876-ea7d-411e-bbc0-96526ab2de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from contextlib import contextmanager\n",
    "\n",
    "    @contextmanager\n",
    "    def silence(stdout=True, stderr=True):\n",
    "        import sys\n",
    "        if stdout:\n",
    "            original_stdout = sys.stdout\n",
    "            sys.stdout\n",
    "        resource = acquire_resource(*args, **kwds)\n",
    "        try:\n",
    "            yield resource\n",
    "        finally:\n",
    "            # Code to release resource, e.g.:\n",
    "            release_resource(resource)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "287522f1-3c42-4e46-a83e-ec2d25ea20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sksurv.metrics\n",
    "import optuna\n",
    "\n",
    "def generic_objective_function(method, X, time, event, eval_times, cv=KFold(n_splits=5)):\n",
    "    cv_scores = []\n",
    "    assert len(eval_times.shape) == 1\n",
    "    \n",
    "    if len(time.shape) == 2: # for multi event only evaluate first (main) event\n",
    "        #assert time.shape[1] == eval_times.shape[0]\n",
    "        main_time = time[:, 0]\n",
    "        main_event = event[:, 0]\n",
    "        #eval_times = eval_times[0]\n",
    "        #print('multi')\n",
    "    else:\n",
    "        main_time = time\n",
    "        main_event = event\n",
    "    \n",
    "    try:\n",
    "        for train_idx, test_idx in cv.split(X):\n",
    "            # silence model output            \n",
    "            #with Silence():\n",
    "            method.fit(X[train_idx], time[train_idx], event[train_idx])\n",
    "            preds = method.predict(X[test_idx], eval_times)\n",
    "            check_probs(method, preds)\n",
    "\n",
    "            assert preds.shape == (len(test_idx), len(eval_times)), f'{preds.shape} != ({len(test_idx)}, {len(eval_times)}) (sample, eval_time)'\n",
    "            for ti, t in enumerate(eval_times):\n",
    "                #print(main_event[test_idx].shape, main_time[test_idx].shape, preds[:, ti].shape)\n",
    "                s = concordance_index_censored(main_event[test_idx], main_time[test_idx], preds[:, ti])[0]\n",
    "                cv_scores.append(s)\n",
    "    except FailedModel as e:\n",
    "        print(f'Failed trial: {e}')\n",
    "        raise optuna.TrialPruned(str(e))\n",
    "    return numpy.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f37c86f-0838-4021-b568-1d71b6c1e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pred(\n",
    "    model, # trained model\n",
    "    datasets, # train and test datasets\n",
    "    eval_times):\n",
    "    \n",
    "    assert len(eval_times.shape) == 1, 'for now only evaluate first (main) event'\n",
    "\n",
    "    X_test, time_test, event_test = datasets['test']\n",
    "    _, time_train, event_train = datasets['train']\n",
    "    \n",
    "    preds = model.predict(X_test, eval_times)\n",
    "\n",
    "    if len(time_train.shape) == 2:\n",
    "        # select only first (main) event\n",
    "        if len(preds.shape) == 3:\n",
    "            assert preds.shape[1] == time_train.shape[1]\n",
    "            preds = preds[:, 0]\n",
    "        time_test, event_test, time_train, event_train = (\n",
    "            x[:, 0] for x in [time_test, event_test, time_train, event_train])\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    #competing = numpy.any(event_train == 2)\n",
    "    event_test = event_as_bool(event_test)\n",
    "    \n",
    "    y = surv_vector(time_test, event_test)\n",
    "    y_train = surv_vector(time_train, event_train)\n",
    "    acc = {}\n",
    "    \n",
    "    max_censor_time = numpy.max(y['time'][~y['event']])\n",
    "    for ti, t in enumerate(eval_times):\n",
    "        p = preds[:, ti]\n",
    "        assert t < max_censor_time\n",
    "        acc[('concordance_index_censored', ti, t)] = concordance_index_censored(y['event'], y['time'], p)[0]\n",
    "        acc[('cumulative_dynamic_auc', ti, t)] = sksurv.metrics.cumulative_dynamic_auc(y_train, y, p, [t])[1]\n",
    "        acc[('raw_brier_score', ti, t)] = my_brier(y, p, t)\n",
    "        acc[('concordance_index_ipcw', ti, t)] = sksurv.metrics.concordance_index_ipcw(y_train, y, p, tau=max_censor_time)[0]\n",
    "        acc[('concordance_index_ipcw_t', ti, t)] = sksurv.metrics.concordance_index_ipcw(y_train, y, p, tau=t)[0]\n",
    "        #acc[('brier_score', ti, t)] = sksurv.metrics.brier_score(y_train, y, 1 - p, [t])[1][0]\n",
    "        \n",
    "    scores = pandas.Series(acc, name='VALUE', dtype=float)\n",
    "    scores.index.names = ['METRIC', 'ITIME', 'TIME']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d542d652-f8da-4fbb-831b-c84051a35428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def optimize_model(method, X, time, event, max_trials=None, study_name=None, time_quantiles=[0.1, 0.25, 0.5, 0.75, 0.9], seed=0, skip_eval=False):\n",
    "    X, time, event = to_numpy(X, time, event)\n",
    "    eval_times = get_time_quantiles(time, event, q=time_quantiles)\n",
    "    train_test_ds = preproc_for_prediction(X, time, event, seed=seed)\n",
    "\n",
    "    if len(time.shape) == 2: # multi state\n",
    "        assert eval_times.shape[0] == time.shape[1]\n",
    "        eval_times = eval_times[0] # only evaluate first (main) event\n",
    "    \n",
    "    #global study\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize', sampler=optuna.samplers.RandomSampler(seed=seed), study_name=study_name, load_if_exists=True,\n",
    "        storage=(f'sqlite:///{work_dir}/{study_name}.optuna.sqlite3' if study_name is not None else None))\n",
    "    \n",
    "    def count_complete():\n",
    "        return sum(t.state == optuna.trial.TrialState.COMPLETE for t in study.trials)\n",
    "    \n",
    "    from collections import Counter\n",
    "    trial_counts = dict(Counter(str(t.state).split('.')[1] for t in study.trials))\n",
    "        \n",
    "    if True:\n",
    "        print('Loaded', len(study.trials), 'trials:', ', '.join(f'{n} {s}' for s, n in trial_counts.items()))\n",
    "\n",
    "    if max_trials is None or count_complete() < max_trials:\n",
    "        print(count_complete(), 'of', max_trials, 'completed')\n",
    "    while max_trials is None or count_complete() < max_trials:\n",
    "        study.optimize(lambda trial: generic_objective_function(method(trial), *train_test_ds['train'], eval_times), n_trials=1)\n",
    "    \n",
    "    if skip_eval:\n",
    "        return pandas.Series(dtype='float64'), trial_counts\n",
    "    try:\n",
    "        best_trial = study.best_trial\n",
    "    except ValueError:\n",
    "        print('No trials to evaluate')\n",
    "        return pandas.Series(dtype='float64'), trial_counts\n",
    "    \n",
    "    #print('Test best model')\n",
    "    model = None\n",
    "    if study_name is not None:\n",
    "        model_key = hash_dict(best_trial.params)\n",
    "        model_cache_path = f'{work_dir}/{study_name}.models.pickle.gz'\n",
    "        try:\n",
    "            model_cache = load_or_new(dict, model_cache_path)\n",
    "        except RuntimeError as e: # this could be due to a torch model saved on an unavailable device\n",
    "            print('Error loading model (will be retrained):', e)\n",
    "            model_cache = {}\n",
    "        model = model_cache.get(model_key)\n",
    "        \n",
    "    \n",
    "    if model is None:\n",
    "        #print('Train best model')\n",
    "        model = method(best_trial).fit(*train_test_ds['train'])\n",
    "        if study_name is not None:\n",
    "            model_cache[model_key] = model\n",
    "            dump_to(model_cache, model_cache_path)\n",
    "\n",
    "    return evaluate_pred(model, train_test_ds, eval_times), trial_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39dafe-9503-44da-91ac-b1f57d56d391",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bda6841-0cd5-400b-9016-8494492bb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89e04464-916d-489d-ac94-0a7ac7f5cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurvMethod:\n",
    "    independent = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        raise NotImplementedError()\n",
    "    def __init__(self, trial):\n",
    "        self.trial = trial\n",
    "        self.model_params = self.trial2model_params(trial)\n",
    "    def fit(self, X, times, events):\n",
    "        \"\"\"X: sample, feat\n",
    "        times: sample, event\n",
    "        events: sample, event\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "    def predict(self, X, eval_times):\n",
    "        \"\"\"predict probabilites of event up to given times for each event, with shape (sample, event, eval_time)\"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac826b-0287-4f78-b8ac-8632cf6b1d02",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scikit Survival Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d05765ac-b29b-44cb-9284-6cc425397321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkSurvMethod(SurvMethod):\n",
    "    \"\"\"Generic wrapper for a Scikit Survival model\"\"\"\n",
    "    model_func = None\n",
    "    competing = False\n",
    "    multi = False\n",
    "\n",
    "    def fit(self, X, times, events):\n",
    "        y = surv_vector(times, events)\n",
    "        #print(y.shape, y)\n",
    "        self.model_ = self.model_func(**self.model_params).fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, eval_times):\n",
    "        \"\"\"predict probabilites of event up to given times for each event\"\"\"\n",
    "        return numpy.array([[1 - sf(t) for t in eval_times] for sf in self.model_.predict_survival_function(X)])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d259169b-d429-4d7c-8c9f-46a4b57aa499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkSurvMultiMethod(SurvMethod):\n",
    "    \"\"\"This class is similar to SkSurvMethod but creates a Scikit Survival model with the same parameters for each event independently\"\"\"\n",
    "    model_func = None\n",
    "\n",
    "    def fit(self, X, times, events):\n",
    "        Y = surv_matrices(times, events)\n",
    "        self.models_ = []\n",
    "        for y in Y:\n",
    "            m = self.model_func(**self.model_params)\n",
    "            m.fit(X, y)\n",
    "            self.models_.append(m)\n",
    "        return self\n",
    "    def predict(self, X, eval_times):\n",
    "        \"\"\"predict probabilites of event up to given times for each event\"\"\"\n",
    "        return numpy.swapaxes([[[1 - sf(t) for t in tt] for sf in m.predict_survival_function(X)] for tt, m in zip(eval_times, self.models_)], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2e41746-e517-4a05-9b65-fb3c01ee4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkCoxPH(SkSurvMethod):\n",
    "    short_name = 'skcoxph'\n",
    "    long_name = 'Cox PH'\n",
    "    from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "    model_func = CoxPHSurvivalAnalysis\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        return dict(\n",
    "            alpha=trial.suggest_float('alpha', 0, 10),\n",
    "            ties=trial.suggest_categorical('ties', [\"breslow\", \"efron\"]),\n",
    "            n_iter=10000, tol=1e-09, verbose=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "587924d1-df29-48a9-b494-873faf66766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkRSF(SkSurvMethod):\n",
    "    short_name = 'skrsf'\n",
    "    long_name = 'Random Survival Forest'\n",
    "\n",
    "    from sksurv.ensemble import RandomSurvivalForest\n",
    "    model_func = RandomSurvivalForest\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        return dict(\n",
    "            n_estimators = 1000, #trial.suggest_int('n_estimators', 100, 1000, 100),\n",
    "            max_depth    = trial.suggest_int('max_depth ', 1, 5),\n",
    "            n_jobs=n_jobs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186ad98-1d6e-46fa-a90a-65feee118761",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deep Survival Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e47aa4bd-4835-4602-817b-b8acd680bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./auton-survival')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4938815-e849-419e-b2ef-5f4a2968f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def generate_layer_sizes(trial, min_hidden_layers=0, max_hidden_layers=4, max_log2_size=8, prefix=''):\n",
    "        layers = []\n",
    "        for i in range(trial.suggest_int(f'{prefix}n_hidden', min_hidden_layers, max_hidden_layers)):\n",
    "            size = trial.suggest_int(f'{prefix}log2_layer_{i}', 0, max_log2_size)\n",
    "            layers.append(2**size)\n",
    "            max_log2_size = size\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "554b9a8c-65bb-44db-9c6f-d10657493157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSurvivalMachines(SurvMethod):\n",
    "    short_name = 'dsm'\n",
    "    long_name = 'Deep Survival Machines'\n",
    "    competing = True\n",
    "    multi = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        return dict(\n",
    "            mod = dict(\n",
    "                k             = trial.suggest_int('k', 1, 6),\n",
    "                distribution  = trial.suggest_categorical('distribution', ['LogNormal', 'Weibull']),\n",
    "                layers        = generate_layer_sizes(trial, max_hidden_layers=4, max_log2_size=8),\n",
    "            ),\n",
    "            fit = dict(\n",
    "                learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),\n",
    "                vsize         = trial.suggest_float('val_size', 0.05, 0.5, log=True),\n",
    "                batch_size    = 2**trial.suggest_int('batch_size', 2, 10),\n",
    "                elbo          = trial.suggest_categorical('elbo', [True, False]),\n",
    "                optimizer     = trial.suggest_categorical('optimizer', ['Adam', 'RMSProp', 'SGD']),\n",
    "                iters         = 2**trial.suggest_int('max_epochs', 3, 10),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def fit(self, X, times, events):\n",
    "        import sys\n",
    "        \n",
    "        from auton_survival.models.dsm import DeepSurvivalMachines\n",
    "        try:\n",
    "            self.model_ = DeepSurvivalMachines(\n",
    "                **self.model_params['mod']).fit(\n",
    "                X, times, events, **self.model_params['fit'])\n",
    "        except RuntimeError as e:\n",
    "            raise FailedModel(f'{self.short_name} model fit failed: {e}')\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, eval_times):\n",
    "        \"\"\"predict probabilites of event up to given times for each event\"\"\"\n",
    "        #global dbg\n",
    "        #dbg = self.model_, X, eval_times, numpy.swapaxes([self.model_.predict_risk(X, t)[:, 0] for t in eval_times], 0, 1)\n",
    "        return numpy.swapaxes([self.model_.predict_risk(X, t)[:, 0] for t in eval_times], 0, 1)\n",
    "        #return numpy.nan_to_num(numpy.swapaxes([self.model_.predict_risk(X, t)[:, 0] for t in eval_times], 0, 1), nan=0.5, posinf=1, neginf=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e895df2-d9b2-4f9c-a6a9-71c3b4196079",
   "metadata": {
    "tags": []
   },
   "source": [
    "### pycox models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d56dcbc-83d7-406a-bac8-d8c3ddfc3797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './pycox')\n",
    "sys.path.insert(0, './torchtuples')\n",
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "import torch\n",
    "import torchtuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e52578e-e7bd-48e1-b51b-c03a5977a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabTransformCompeting(LabTransDiscreteTime):\n",
    "    def transform(self, durations, events):\n",
    "        durations, is_event = super().transform(durations, events > 0)\n",
    "        events[is_event == 0] = 0\n",
    "        return durations, events.astype('int64')\n",
    "\n",
    "class CauseSpecificNet(torch.nn.Module):\n",
    "    \"\"\"Network structure similar to the DeepHit paper, but without the residual\n",
    "    connections (for simplicity).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, num_nodes_shared, num_nodes_indiv, num_risks,\n",
    "                 out_features, batch_norm=True, dropout=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        self.shared_net = torchtuples.practical.MLPVanilla(\n",
    "            in_features, num_nodes_shared[:-1], num_nodes_shared[-1],\n",
    "            batch_norm, dropout,\n",
    "        )\n",
    "        self.risk_nets = torch.nn.ModuleList()\n",
    "        for _ in range(num_risks):\n",
    "            net = torchtuples.practical.MLPVanilla(\n",
    "                num_nodes_shared[-1] + (in_features if residual else 0), \n",
    "                num_nodes_indiv, out_features,\n",
    "                batch_norm, dropout,\n",
    "            )\n",
    "            self.risk_nets.append(net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.shared_net(input)\n",
    "        if hasattr(self, 'residual') and self.residual:\n",
    "            out = torch.cat([out, input], dim=-1)\n",
    "        out = [net(out) for net in self.risk_nets]\n",
    "        out = torch.stack(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b0ebd37-5aa8-4e6b-b8bf-c749100d9bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepHitMethod(SurvMethod):\n",
    "    short_name = 'deephit'\n",
    "    long_name = 'DeepHit'\n",
    "    multi = False\n",
    "    competing = True\n",
    "    residual = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        layer_sizes  = generate_layer_sizes(trial, min_hidden_layers=1, max_hidden_layers=4, max_log2_size=8)\n",
    "        shared_layers_num = trial.suggest_int('shared_layers_num', 1, len(layer_sizes))\n",
    "        \n",
    "        return dict(\n",
    "            num_durations = trial.suggest_int('num_durations', 10, 50, step=10),\n",
    "\n",
    "            net = dict(\n",
    "                batch_norm = trial.suggest_categorical('batch_norm', [True, False]),\n",
    "                dropout    = trial.suggest_float('dropout', 0.01, 0.5, log=True),\n",
    "            ),\n",
    "            indepnet = dict(\n",
    "                num_nodes  = layer_sizes,\n",
    "            ),\n",
    "            compnet = dict(\n",
    "                num_nodes_shared = layer_sizes[:shared_layers_num],\n",
    "                num_nodes_indiv  = layer_sizes[shared_layers_num:],\n",
    "                #residual         = trial.suggest_categorical('batch_norm', [True, False]),\n",
    "            ),\n",
    "            mod = dict(\n",
    "                alpha                  = trial.suggest_float('alpha', 1e-3, 1e-2, log=True),\n",
    "                sigma                  = trial.suggest_float('sigma', 1e-2, 1, log=True),\n",
    "            ),\n",
    "            opt = dict(\n",
    "                lr                     = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "                decoupled_weight_decay = trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True),\n",
    "                cycle_eta_multiplier   = trial.suggest_float('eta_multiplier',0.2,1),\n",
    "            ),\n",
    "            fit = dict(\n",
    "                epochs        = 2**trial.suggest_int('epochs_log2', 2, 5),\n",
    "                batch_size    = 2**trial.suggest_int('batch_log2', 3, 8),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def fit(self, X, times, events):\n",
    "        from pycox.models import DeepHitSingle, DeepHit\n",
    "\n",
    "        assert len(events.shape) == 1\n",
    "        num_risks = numpy.max(events.astype(float))\n",
    "        assert num_risks == int(num_risks)\n",
    "        num_risks = int(num_risks)\n",
    "        self.num_risks_ = num_risks\n",
    "        \n",
    "        optimizer = torchtuples.optim.AdamWR(**self.model_params['opt'])\n",
    "        #print('fit', num_risks, times.shape, events.shape)\n",
    "        if num_risks == 1:\n",
    "            self.labtrans_ = DeepHitSingle.label_transform(self.model_params['num_durations'])\n",
    "            y = self.labtrans_.fit_transform(times, events)\n",
    "            net = torchtuples.practical.MLPVanilla(\n",
    "                in_features=X.shape[1], out_features=self.labtrans_.out_features, \n",
    "                **self.model_params['indepnet'], **self.model_params['net'])\n",
    "            method = DeepHitSingle\n",
    "        else:\n",
    "            self.labtrans_ = LabTransformCompeting(self.model_params['num_durations'])\n",
    "            y = self.labtrans_.fit_transform(times, events)\n",
    "            net = CauseSpecificNet(\n",
    "                in_features=X.shape[1], out_features=self.labtrans_.out_features, num_risks=num_risks, \n",
    "                **self.model_params['compnet'], **self.model_params['net'], residual=self.residual)\n",
    "            method = DeepHit\n",
    "        \n",
    "        self.model_ = method(net, optimizer, **self.model_params['mod'], device=torch_device, duration_index=self.labtrans_.cuts)\n",
    "        self.model_.fit(X.astype('float32'), y, num_workers=0 if True else n_jobs, verbose=False, **self.model_params['fit'])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, eval_times):\n",
    "        preds = 1 - self.model_.predict_surv(X.astype('float32'))\n",
    "        if hasattr(self, 'num_risks_') and self.num_risks_ > 1:\n",
    "            preds = preds.T\n",
    "        #print('predict', eval_times.shape, self.labtrans_.cuts.shape, preds.shape)\n",
    "        return numpy.array([numpy.interp(eval_times, self.labtrans_.cuts, p, left=0, right=1) for p in preds])\n",
    "#test_methods([DeepHitMethod])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb30f0fa-fb78-4b77-bf14-98fab42c534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepHitMethodRes(DeepHitMethod):\n",
    "    short_name = 'deephitres'\n",
    "    long_name = 'DeepHitRes'\n",
    "    residual = True\n",
    "    independent = False\n",
    "#test_methods([DeepHitMethodRes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3e9b695-e44e-4a4f-b19b-b6dd0499afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSurvMethod(SurvMethod):\n",
    "    short_name = 'deepsurv'\n",
    "    long_name = 'DeepSurv'\n",
    "    multi = False\n",
    "    competing = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        return dict(\n",
    "            net = dict(\n",
    "                num_nodes  = generate_layer_sizes(trial, min_hidden_layers=1, max_hidden_layers=4, max_log2_size=8),\n",
    "                batch_norm = trial.suggest_categorical('batch_norm', [True,False]),\n",
    "                dropout    = trial.suggest_float('dropout', 0.01, 0.5, log=True),\n",
    "            ),\n",
    "            opt = dict(\n",
    "                lr                     = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "                decoupled_weight_decay = trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True),\n",
    "                cycle_eta_multiplier   = trial.suggest_float('eta_multiplier',0.2,1),\n",
    "            ),\n",
    "            fit = dict(\n",
    "                epochs        = 2**trial.suggest_int('epochs_log2', 2, 5),\n",
    "                batch_size    = 2**trial.suggest_int('batch_log2', 3, 8),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def fit(self, X, times, events):\n",
    "        from pycox.models import CoxPH\n",
    "        \n",
    "        optimizer = torchtuples.optim.AdamWR(**self.model_params['opt'])\n",
    "\n",
    "        self.utimes_ = sorted(set(times))\n",
    "        \n",
    "        net = torchtuples.practical.MLPVanilla(\n",
    "            in_features=X.shape[1], out_features=1, output_bias=False,\n",
    "            **self.model_params['net'],\n",
    "        )\n",
    "        \n",
    "        self.model_ = CoxPH(net, optimizer, device=torch_device)#, **self.model_params['mod'], device=torch_device, duration_index=self.labtrans_.cuts)\n",
    "        self.model_.fit(X.astype('float32'), (times, events), num_workers=0 if True else n_jobs, verbose=False, **self.model_params['fit'])\n",
    "        self.model_.compute_baseline_hazards()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X, eval_times):\n",
    "        preds = 1 - self.model_.predict_surv(X.astype('float32'))\n",
    "        return numpy.array([numpy.interp(eval_times, self.utimes_, p, left=0, right=1) for p in preds])\n",
    "#test_methods([DeepSurvMethod])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cc5d3-14e7-4106-9928-cc8a1049c5c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SurvTRACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bce9761-9570-40b6-9c3a-d97aa8d660ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./SurvTRACE')\n",
    "sys.path.append('./easydict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e471aa20-787a-4e76-9315-286655b110af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # prova per capire i competing events\n",
    "    from survtrace import STConfig\n",
    "    from survtrace.dataset import load_data\n",
    "    STConfig['data']='seer'\n",
    "    load_data(STConfig)\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcf76b36-9ff5-4db2-87b5-ccc82a3adf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbg = None\n",
    "class SurvTraceMethod(SurvMethod):\n",
    "    short_name = 'survtrace'\n",
    "    long_name = 'SurvTRACE'\n",
    "    multi = False\n",
    "    competing = False # TODO add competing!\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        # Got the error: \"The hidden size (16) is not a multiple of the number of attention heads (6)\"\n",
    "        # So the hidden size is now a multiple of the attention head number\n",
    "        num_attention_heads  = trial.suggest_int('num_attention_heads', 2, 6)\n",
    "        return dict(\n",
    "            conf = dict(\n",
    "                hidden_size          = num_attention_heads*trial.suggest_int('hidden_size_log2', 1, 6), \n",
    "                intermediate_size    = 2**trial.suggest_int('intermediate_size_log2', 3, 7),\n",
    "                hidden_dropout_proba = trial.suggest_float('hidden_dropout_proba', 1e-3, 0.5, log=True),\n",
    "                num_hidden_layers    = trial.suggest_int('num_hidden_layers', 1, 4),\n",
    "                num_attention_heads  = num_attention_heads,\n",
    "            ),\n",
    "            fit = dict(\n",
    "                learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "                epochs        = 2**trial.suggest_int('epochs_log2', 2, 6),\n",
    "                batch_size    = 2**trial.suggest_int('batch_size_log2', 3, 8),\n",
    "                weight_decay  = trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def fit(self, X, times, events):\n",
    "        from survtrace.utils import LabelTransform\n",
    "        from survtrace import STConfig, Trainer\n",
    "        from survtrace.model import SurvTraceSingle\n",
    "        \n",
    "        assert len(events.shape) == 1\n",
    "        num_risks = numpy.max(events.astype(float))\n",
    "        assert num_risks == int(num_risks)\n",
    "        num_risks = int(num_risks)\n",
    "\n",
    "        # data preprocessing\n",
    "        self.labtrans_ = LabelTransform(cuts=numpy.array(\n",
    "            [times.min()] +\n",
    "            numpy.quantile(times[events == 1], STConfig['horizons']).tolist() +\n",
    "            [times.max()]\n",
    "        ))\n",
    "        self.labtrans_.fit(times, events)\n",
    "        y = self.labtrans_.transform(times, events)\n",
    "        \n",
    "        if num_risks == 1:\n",
    "            ydf = pandas.DataFrame({\"duration\": y[0], \"event\": y[1], \"proportion\": y[2]})\n",
    "        else:\n",
    "            print('num_risks:', num_risks)\n",
    "            ydf = pandas.DataFrame({\"duration\": y[0], \"proportion\": y[2]})\n",
    "            for evt in range(num_risks):\n",
    "                ydf['event_' + str(evt)] = (events == (evt + 1)).astype(float)\n",
    "            print(pandas.concat([ydf, pandas.DataFrame({'events': events, 'y[1]': y[1]})], axis=1).head(20))\n",
    "                \n",
    "\n",
    "        STConfig['labtrans'] = self.labtrans_\n",
    "        STConfig['num_numerical_feature'] = X.shape[1]\n",
    "        STConfig['num_categorical_feature'] = 0 #int(len(cols_categorical))\n",
    "        STConfig['num_feature'] = X.shape[1]\n",
    "        STConfig['vocab_size'] = 0\n",
    "        STConfig['duration_index'] = self.labtrans_.cuts\n",
    "        STConfig['out_feature'] = int(self.labtrans_.out_features)\n",
    "        \n",
    "        STConfig['num_event'] = num_risks\n",
    "        \n",
    "        STConfig.update(self.model_params['conf'])\n",
    "        self.model_ = SurvTraceSingle(STConfig)\n",
    "        \n",
    "        # initialize a trainer\n",
    "        trainer = Trainer(self.model_)\n",
    "        train_loss, val_loss = trainer.fit((pandas.DataFrame(X.astype('float32')), ydf), **self.model_params['fit'])\n",
    "        #global dbg\n",
    "        #dbg = self, X, y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, eval_times):\n",
    "        preds = 1 - self.model_.predict_surv(pandas.DataFrame(X.astype('float32')))\n",
    "        return numpy.array([numpy.interp(eval_times, self.labtrans_.cuts, p, left=0, right=1) for p in preds.cpu()])\n",
    "#test_methods([SurvTraceMethod], event_mode='competing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e52e7a-a638-4a85-806b-d90ec7cdcfc0",
   "metadata": {},
   "source": [
    "### Modello mio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c418f092-f18f-4dee-861b-3f9bb9f727a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, interaction_size, hidden_activation=torch.nn.ReLU, **kwargs):\n",
    "        super().__init__()\n",
    "        self.enc1 = FFN(input_size, interaction_size, output_activation=hidden_activation, **kwargs)\n",
    "        self.enc2 = FFN(input_size, interaction_size, output_activation=hidden_activation, **kwargs)\n",
    "        self.ffn = FFN(interaction_size**2, output_size, hidden_activation=hidden_activation, **kwargs)\n",
    "    def forward(self, x):\n",
    "        l1 = self.enc1(x).unsqueeze(-1)\n",
    "        l2 = self.enc2(x).unsqueeze(-2)\n",
    "        ll = (l1*l2).flatten()\n",
    "        return self.ffn(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9d6a56a-0bca-4af1-8cb0-3de063886010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SURVTORCH(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size,\n",
    "            times,\n",
    "            interaction_size=None,\n",
    "            **ffn_kwargs,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.times = times\n",
    "        self.delta_times = times[1:] - times[:-1]\n",
    "        assert len(self.times.shape) == 2\n",
    "        output_size = self.times.shape[0]*self.times.shape[1]\n",
    "        if interaction_size is None:\n",
    "            self.net = FFN(\n",
    "                input_size, output_size, \n",
    "                output_activation=None,\n",
    "                **ffn_kwargs,\n",
    "            )\n",
    "        else:\n",
    "            self.net = InterNN(\n",
    "                input_size, output_size, \n",
    "                interaction_size=interaction_size,\n",
    "                output_activation=None,\n",
    "                **ffn_kwargs,\n",
    "            )\n",
    "\n",
    "        \n",
    "    def forward(self, x, times=None):\n",
    "        # times should be 1-dimensional!\n",
    "        y = self.net(x).reshape(-1, *self.times.shape)\n",
    "        y = torch.nn.functional.softmax(y, 1)\n",
    "        if times is None:\n",
    "            return y\n",
    "\n",
    "        acc = []\n",
    "        for t in times:                \n",
    "            interval_weights = torch.clamp((t - self.times[:-1])/self.delta_times, 0, 1)\n",
    "            inf_weigths = 1 - 2**-torch.clamp(t/self.times[-1] - 1, 0)\n",
    "            weights = torch.cat([interval_weights, inf_weigths.reshape(1, -1)])\n",
    "            survival = torch.sum(y*weights.reshape(1, *weights.shape), -2)\n",
    "            acc.append(survival.reshape(-1, self.times.shape[1], 1))\n",
    "        return torch.cat(acc, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d04864eb-e2fa-45a3-a3b7-eac6a5dda0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe move most of this code to SURVTORCH\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "#from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import dataclasses\n",
    "\n",
    "def time_quantiles(y_times, y_events, quantiles):\n",
    "    try:\n",
    "        quantiles = numpy.linspace(0, 1, quantiles + 1)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    return numpy.array([\n",
    "        numpy.quantile(y_times[y_events[:, i], i], quantiles)\n",
    "        for i in range(y_times.shape[1])\n",
    "    ]).T\n",
    "\n",
    "@dataclasses.dataclass(eq=False)#, kw_only=True)\n",
    "class GBSURV(sklearn.base.BaseEstimator):\n",
    "    time_bins: int = 10\n",
    "    epochs: int = 10\n",
    "    learning_rate: float = 1e-4\n",
    "    batch_size: int = 64\n",
    "    ffn_params: dict = dataclasses.field(default_factory=dict)\n",
    "    interaction_size: int = None\n",
    "    device: str = 'cpu'\n",
    "    #hidden_sizes: list = dataclasses.field(default_factory=list)\n",
    "    #dropout: float = 0.1\n",
    "    #hidden_activation=torch.nn.ReLU    \n",
    "    \n",
    "    def as_tensor(self, x): # maybe move this to SURVTORCH\n",
    "        return torch.from_numpy(x.astype(numpy.float32)).to(self.device)\n",
    "        \n",
    "    def fit(self, X, y_times, y_events, X_test=None, y_test_times=None, y_test_events=None, test_times=None):\n",
    "        assert numpy.any(y_events), f'no event in {y_events.shape}'\n",
    "        self.time_breaks_ = time_quantiles(y_times, y_events, self.time_bins)\n",
    "        \n",
    "        model = SURVTORCH(\n",
    "            input_size=X.shape[1], \n",
    "            times=self.as_tensor(self.time_breaks_),\n",
    "            **self.ffn_params,\n",
    "        ).to(self.device)\n",
    "\n",
    "        dl = torch.utils.data.DataLoader(\n",
    "            torch.utils.data.TensorDataset(\n",
    "                self.as_tensor(X), self.as_tensor(y_times),\n",
    "                torch.from_numpy(y_events.astype(bool)).to(self.device),\n",
    "            ), \n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        \n",
    "        opt = torch.optim.Adam(model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        \n",
    "        times0 = y_times[y_events] # sample times\n",
    "        if times0.shape[0] == 0:\n",
    "            print(y_times, y_times.shape)\n",
    "            print(times0, times0.shape)\n",
    "            print(y_events, y_events.shape)\n",
    "        assert times0.shape[0] > 0, f'sampling times are empty: {times0}'\n",
    "        \n",
    "        self.train_history = []\n",
    "        if X_test is not None:\n",
    "            if test_times is None:\n",
    "                test_times = time_quantiles(y_test_times, y_test_events, [0.25, 0.50, 0.75])\n",
    "            X_test = self.as_tensor(X_test)\n",
    "            y_test_times = self.as_tensor(y_test_times)\n",
    "            y_test_events = torch.from_numpy(y_test_events.astype(bool))\n",
    "        \n",
    "        \n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            #print(f\"Epoch: {epoch + 1}\")\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            epoch_history = {'train losses': []}\n",
    "            for X, y_times, y_events in dl:\n",
    "                # chose random time for training\n",
    "                t = times0[torch.randint(0, times0.shape[0], ())]\n",
    "\n",
    "                p = model(X, [t])[:, :, 0]\n",
    "                \n",
    "                informative = ((y_times > t) | y_events).to(torch.float32)\n",
    "                events = ((y_times <= t) & y_events).to(torch.float32)\n",
    "                loss = torch.nn.functional.mse_loss(\n",
    "                    p*informative,\n",
    "                    events,\n",
    "                )\n",
    "\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                epoch_history['train losses'].append(loss.item())\n",
    "            if X_test is not None:\n",
    "                epoch_history['test errors'] = []\n",
    "                model.eval()\n",
    "                err_table = []\n",
    "                with torch.no_grad():\n",
    "                    for event_idx, event_times in enumerate(test_times.T):\n",
    "                        p = model(X_test, event_times)\n",
    "                        event_errs = []\n",
    "                        for i, t in enumerate(event_times):\n",
    "                            p0 = p[:, event_idx, i]\n",
    "                            informative = ((y_test_times[:, event_idx] > t) | y_test_events[:, event_idx]).to(torch.float32)\n",
    "                            events = ((y_test_times[:, event_idx] <= t) & y_test_events[:, event_idx]).to(torch.float32)\n",
    "                            #print(p0.shape, informative.shape, events.shape)\n",
    "                            loss = torch.nn.functional.mse_loss(\n",
    "                                p0*informative,\n",
    "                                events,\n",
    "                            )\n",
    "                            informative = (y_test_times[:, event_idx] > t) | y_test_events[:, event_idx]\n",
    "                            events = (y_test_times[:, event_idx] <= t) & y_test_events[:, event_idx]\n",
    "                            score = torch.nn.functional.mse_loss(p0[informative], events[informative])\n",
    "                            #print(informative.shape)\n",
    "                            #assert False\n",
    "                            event_errs.append(score.item())\n",
    "                            #print(loss)\n",
    "                        epoch_history['test errors'].append(event_errs)\n",
    "            self.train_history.append(epoch_history)\n",
    "                \n",
    "        self.model_ = model\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, times=None):\n",
    "        self.model_.eval()\n",
    "        return self.model_(self.as_tensor(X), times).detach().cpu().numpy()\n",
    "        \n",
    "#from sklearn.utils.estimator_checks import check_estimator\n",
    "#check_estimator(SURV())\n",
    "#est = SURV(arch='MMM', time_bins=10, epochs=200).fit(X_train, y_train_times, y_train_events, X_test, y_test_times, y_test_events)\n",
    "#est = SURV(arch='MMM', time_bins=10, epochs=2000, hidden_sizes=[64, 16], nn_params=dict(embed_size=64, dropout=0.1)).fit(X_train, y_train_times, y_train_events, X_test, y_test_times, y_test_events)\n",
    "#est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b481f6bc-14ba-487c-ae32-368604143fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBM(SurvMethod):\n",
    "    short_name = 'gbm'\n",
    "    long_name = 'gbm'\n",
    "    multi = True\n",
    "    competing = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        return dict(\n",
    "            time_bins = trial.suggest_int('num_durations', 3, 30),\n",
    "            epochs        = 2**trial.suggest_int('epochs_log2', 2, 5),\n",
    "            batch_size    = 2**trial.suggest_int('batch_log2', 3, 8),\n",
    "            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "\n",
    "            ffn_params = dict(\n",
    "                hidden_sizes      = generate_layer_sizes(trial, max_hidden_layers=4, max_log2_size=8),\n",
    "                dropout           = trial.suggest_float('dropout', 0.01, 0.5, log=True),\n",
    "                hidden_activation = suggest_activation(trial, 'activation'),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def fit(self, X, times, events):\n",
    "        \n",
    "        if len(times.shape) == 1:\n",
    "            times = times[:, None]\n",
    "            events = events[:, None]\n",
    "        assert times.shape[0] > times.shape[1], f'too many events: {times.shape[1]} events but only {times.shape[0]} observations'\n",
    "        \n",
    "        self.model_ = GBSURV(**self.model_params, device=torch_device)\n",
    "        self.model_.fit(X, times, events)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X, eval_times):\n",
    "        return self.model_.predict(X, eval_times)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97213694-984a-46d2-a8f2-6293f41c8e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBMInter(GBM):\n",
    "    short_name = 'gbmi'\n",
    "    long_name = 'gbmi'\n",
    "    multi = True\n",
    "    competing = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        p = GBM.trial2model_params(trial)\n",
    "        p['interaction_size'] = trial.suggest_int('interaction_size_log2', 2, 6)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03af853e-1bc9-4867-8182-fba783b793aa",
   "metadata": {},
   "source": [
    "### Albero/Cox (Piero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72375187-4eff-4791-86ae-7a9a7d29e8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8329291a-ffff-442e-b186-aa1b05590e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qui ho provato a fare una versione\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class PieroReg:\n",
    "    max_depth: int = None\n",
    "    min_samples_leaf: int = 10\n",
    "    base_regressor: object = LinearRegression()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classifier_ = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf)\n",
    "        self.classifier_.fit(X, y)\n",
    "        clusters = self.classifier_.apply(X)\n",
    "        self.regressors_ = {}\n",
    "        for c in numpy.unique(clusters):\n",
    "            idx = clusters == c\n",
    "            self.regressors_[c] = clone(self.base_regressor).fit(X[idx], y[idx])\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = numpy.full(len(X), numpy.nan)\n",
    "        clusters = self.classifier_.apply(X)\n",
    "        for c in numpy.unique(clusters):\n",
    "            idx = clusters == c\n",
    "            pred[idx] = self.regressors_[c].predict(X[idx])\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eea3fb-8f01-45c5-bc9a-1ccd423d4e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac92a421-a217-468e-83e1-dfd178ac4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class PieroCox:\n",
    "    max_depth: int = None\n",
    "    min_samples_leaf: int = 10\n",
    "    alpha: float = 1.0\n",
    "    l1_ratio: float = 0.5\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classifier_ = DecisionTreeRegressor(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf)\n",
    "        self.classifier_.fit(X[y['event']], y['time'][y['event']])\n",
    "        clusters = self.classifier_.apply(X)\n",
    "        self.regressors_ = {}\n",
    "        for c in numpy.unique(clusters):\n",
    "            idx = clusters == c\n",
    "            self.regressors_[c] = CoxnetSurvivalAnalysis(alphas=[self.alpha], l1_ratio=self.l1_ratio, fit_baseline_model=True).fit(X[idx], y[idx])\n",
    "        return self\n",
    "\n",
    "    def predict_survival_function(self, X):\n",
    "        pred = numpy.full(len(X), None)\n",
    "        clusters = self.classifier_.apply(X)\n",
    "        for c in numpy.unique(clusters):\n",
    "            idx = clusters == c\n",
    "            pred[idx] = self.regressors_[c].predict_survival_function(X[idx])\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6817fb95-f917-4874-ad01-08e9c2a60279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PieroMethod(SurvMethod):\n",
    "    short_name = 'piero'\n",
    "    long_name = 'Albero/Cox (Piero)'\n",
    "    competing = False\n",
    "    multi = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def trial2model_params(trial):\n",
    "        return dict(            \n",
    "            max_depth = trial.suggest_int('max_depth', 1, 6),\n",
    "            min_samples_leaf = 2**trial.suggest_int('min_samples_leaf_log2', 2, 8),\n",
    "            alpha=trial.suggest_float('alpha', 0.05, 10),\n",
    "            l1_ratio=trial.suggest_float('l1_ratio', 0, 1),\n",
    "            #ties=trial.suggest_categorical('ties', [\"breslow\", \"efron\"]),\n",
    "            #n_iter=10000, tol=1e-09, verbose=0,\n",
    "        )\n",
    "\n",
    "    def fit(self, X, times, events):\n",
    "        y = surv_vector(times, events)\n",
    "        try:\n",
    "            self.model_ = PieroCox(**self.model_params).fit(X, y)\n",
    "        except ArithmeticError as e:\n",
    "            raise FailedModel(f'{self.short_name} model fit failed: {e}')\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, eval_times):\n",
    "        \"\"\"predict probabilites of event up to given times for each event\"\"\"\n",
    "        def sfext(sf, t):\n",
    "            if t <= sf.x[0]:\n",
    "                return 1.0\n",
    "            if t < sf.x[-1]:\n",
    "                return sf(t)\n",
    "            return 0.0\n",
    "        return numpy.array([[1 - sfext(sf, t) for t in eval_times] for sf in self.model_.predict_survival_function(X)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac9eb0-1524-4009-939a-f300674607ef",
   "metadata": {},
   "source": [
    "### SODEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "677c9b9f-76ed-42fc-9824-066b9e1f3bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import sys\n",
    "    sys.path.insert(0, './torchdiffeq')\n",
    "    sys.path.insert(0, './lifelines')\n",
    "    sys.path.insert(0, './autograd')\n",
    "    sys.path.insert(0, './formulaic')\n",
    "    sys.path.insert(0, './interface_meta')\n",
    "    sys.path.insert(0, './astor')\n",
    "    sys.path.insert(0, './autograd-gamma')\n",
    "    sys.path.append('./SODEN')\n",
    "    from SODEN.models import SODENModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a686702-5cc3-48c4-acf6-ab2cb889f752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa19979d-ce0c-4c9b-b1d6-e6596c558a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SODENModel(\n",
    "#    model_config=model_config, feature_size=feature_size, use_embed=use_embed)\n",
    "#model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe4ff5-3d8f-4361-8cc1-5702ecce3767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dab8b954-f13c-4ddb-b8d9-4421cb23891b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12e12832-b187-46d2-bd31-95039b7c9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../brainteaser/survival-2022-05/'\n",
    "work_dir = 'workdir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdf195bd-2aef-499a-ae48-a2d139d51d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_competing(times, main_event, competing_event):\n",
    "    combined_event = main_event.astype(float)\n",
    "    combined_event.loc[(main_event == 0) & (competing_event == 1)] = 2\n",
    "    return times, combined_event\n",
    "\n",
    "def preprocess_outcomes():\n",
    "    df = pandas.read_csv(f'{base_dir}/events.csv', index_col='id')\n",
    "    \n",
    "    # fix zero times, they can be problematic for various methods\n",
    "    time_cols = [c for c in df.columns if c.endswith('_time')]\n",
    "    min_times = df[time_cols].replace(0.0, numpy.nan).min()\n",
    "    df[time_cols] = df[time_cols].replace(0.0, min_times/2)\n",
    "    assert (df[time_cols] > 0).all().all()\n",
    "    events = ['death', 'NIV', 'PEG']\n",
    "    \n",
    "    multi = {}\n",
    "    for i, evt in enumerate(events): \n",
    "        sorted_events = events[i:] + events[:i] # put main event first\n",
    "        multi[evt] = (\n",
    "            df[[e + '_time' for e in sorted_events]],\n",
    "            df[[e + '_event' for e in sorted_events]].astype(bool),\n",
    "        )\n",
    "        \n",
    "    return {\n",
    "        'independent': {evt: (df[f'{evt}_time'], df[f'{evt}_event'].astype(bool)) for evt in events},\n",
    "        'competing': {evt: make_competing(df[f'{evt}_time'], df[f'{evt}_event'], df.death_event) for evt in ['NIV', 'PEG']},\n",
    "        'multi': multi,\n",
    "    }\n",
    "assert all(events.max() == 2 for evt, (times, events) in preprocess_outcomes()['competing'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec221e9b-c1b8-4e23-a1fb-783f31b80548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_methods(methods=[SkCoxPH, SkRSF, DeepHitMethod, DeepSurvivalMachines, SurvTraceMethod, GBM, PieroMethod], event_mode=None):\n",
    "    Xdiag = pandas.read_csv(f'{base_dir}/Xdiag.csv', index_col=0)\n",
    "    outcomes = preprocess_outcomes()\n",
    "\n",
    "    acc = {}\n",
    "    for method in methods:\n",
    "        for outtype, ys in outcomes.items():\n",
    "            if event_mode is None:\n",
    "                do = outtype == 'independent' or getattr(method, outtype)\n",
    "            else:\n",
    "                do = outtype == event_mode\n",
    "            if do:\n",
    "                for evt, y in ys.items():\n",
    "                    #print(method.long_name, outtype, evt)\n",
    "                    acc[(method.long_name, outtype, evt)] = optimize_model(\n",
    "                        method, Xdiag.iloc[:300], *(yy[:300] for yy in y), max_trials=1, \n",
    "                        study_name=None)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ce11f2a-ccb9-4133-ad36-d0a15d39ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def run_par_func(args):\n",
    "    Xdiag, y, seed, method, outtype, evt, skip_eval = args\n",
    "    key = (seed, method.long_name, outtype, evt)\n",
    "    return key, optimize_model(\n",
    "        method, Xdiag, *y, max_trials=trials, \n",
    "        study_name=f'{method.short_name}_diag_{outtype}_{evt}_{seed}', seed=seed, skip_eval=skip_eval)\n",
    "\n",
    "    \n",
    "def run_par(methods, seeds=1, trials=10, skip_eval=False, n_jobs=0):\n",
    "    Xdiag = pandas.read_csv(f'{base_dir}/Xdiag.csv', index_col=0)\n",
    "    outcomes = preprocess_outcomes()\n",
    "    if isinstance(seeds, int):\n",
    "        seeds = list(range(seeds))\n",
    "    \n",
    "    tasks = []\n",
    "    for seed in seeds:\n",
    "        for method in methods:\n",
    "            for outtype, ys in outcomes.items():\n",
    "                if outtype == 'independent' or getattr(method, outtype):\n",
    "                    for evt, y in ys.items():\n",
    "                        tasks.append((Xdiag, y, seed, method, outtype, evt, skip_eval))\n",
    "\n",
    "    metric_acc = {}\n",
    "    trial_acc = {}\n",
    "    if n_jobs > 0:\n",
    "        with multiprocessing.Pool(n_jobs) as p:\n",
    "            for key, values in p.imap_unordered(run_par_func, tasks):\n",
    "                print(key)\n",
    "                metric_acc[key], trial_acc[key] = values\n",
    "    else:\n",
    "        for key, values in map(run_par_func, tasks):\n",
    "            print(key)\n",
    "            metric_acc[key], trial_acc[key] = values\n",
    "\n",
    "\n",
    "    return metric_acc, trial_acc\n",
    "\n",
    "    trial_df = pandas.concat({k: pandas.Series(c) for k, c in trial_acc.items()})\n",
    "    empty_scores = {k: s for k, s in metric_acc.items() if len(s) == 0}\n",
    "    ok_scores = {k: s for k, s in metric_acc.items() if len(s) > 0}\n",
    "    if empty_scores:\n",
    "        print('Empty scores:', empty_scores)\n",
    "        metric_acc = {k: s for k, s in metric_acc.items() if len(s) > 0}\n",
    "    #try:\n",
    "    #    eval_df = None if skip_eval else pandas.concat(metric_acc, names=['SEED', 'METHOD', 'MODE', 'EVENT'])\n",
    "    #except Exception as e:\n",
    "    #    print(f'Error {type(e)}: {e}')\n",
    "    #    eval_df = metric_acc\n",
    "    \n",
    "    return eval_df, trial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ee07387-4324-47d4-947a-c8eed0559f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(trials=None, seeds=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], models='AUTO', skip_eval=False, output='als benchmark results.csv', cores=0, device=None)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    get_ipython()\n",
    "    script = False\n",
    "except NameError:\n",
    "    script = True\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--trials', nargs='+', type=int)\n",
    "parser.add_argument('--seeds', nargs='+', default=list(range(10)), type=int)\n",
    "parser.add_argument('--models', choices=['CUDA', 'CPU', 'BOTH', 'AUTO'], default='AUTO')\n",
    "parser.add_argument('--skip-eval', action='store_true', default=False)\n",
    "parser.add_argument('--output', default='als benchmark results.csv')\n",
    "parser.add_argument('--cores', type=int, default=0)\n",
    "parser.add_argument('--device')\n",
    "\n",
    "args = parser.parse_args(None if script else [])\n",
    "print('args:', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44192fff-e0bb-41d0-b6b7-b42b0e8eafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_lists = dict(\n",
    "    CUDA = [DeepHitMethod, SurvTraceMethod, GBM, DeepHitMethodRes, DeepSurvMethod, GBMInter],\n",
    "    CPU  = [SkCoxPH, DeepSurvivalMachines, PieroMethod],\n",
    ")\n",
    "method_lists['ALL'] = [m for methods in method_lists.values() for m in methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fd31471-33ac-4c27-90ec-df4dea794796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU detected, torch device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if args.device is None:\n",
    "    if torch.cuda.is_available():\n",
    "        torch_device = 'cuda:0'\n",
    "    else:\n",
    "        torch_device = 'cpu'\n",
    "else:\n",
    "    torch_device = args.device\n",
    "\n",
    "detected_device = 'CUDA' if torch_device.startswith('cuda') else 'CPU'\n",
    "print(detected_device, 'detected, torch device:', torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e48703-a0c0-4630-bc0e-69f561515951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required trials: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-20 11:50:46,509]\u001b[0m Using an existing study with name 'deephit_diag_independent_death_0' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 102 trials: 100 COMPLETE, 2 FAIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-20 11:50:47,480]\u001b[0m Using an existing study with name 'deephit_diag_independent_NIV_0' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'DeepHit', 'independent', 'death')\n",
      "Loaded 104 trials: 100 COMPLETE, 1 PRUNED, 3 FAIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-20 11:50:48,121]\u001b[0m Using an existing study with name 'deephit_diag_independent_PEG_0' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'DeepHit', 'independent', 'NIV')\n",
      "Loaded 100 trials: 100 COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-20 11:50:48,672]\u001b[0m Using an existing study with name 'deephit_diag_competing_NIV_0' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'DeepHit', 'independent', 'PEG')\n",
      "Loaded 106 trials: 4 FAIL, 100 COMPLETE, 2 PRUNED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-20 11:50:49,471]\u001b[0m Using an existing study with name 'deephit_diag_competing_PEG_0' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'DeepHit', 'competing', 'NIV')\n",
      "Loaded 100 trials: 100 COMPLETE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-20 11:50:50,149]\u001b[0m Using an existing study with name 'survtrace_diag_independent_death_0' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'DeepHit', 'competing', 'PEG')\n",
      "Loaded 107 trials: 6 FAIL, 100 COMPLETE, 1 RUNNING\n",
      "Error loading model (will be retrained): Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n",
      "GPU not found! will use cpu for training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/archive/home/gbirolo/projects/als-surv-benchmarks/./SurvTRACE/survtrace/utils.py:78: UserWarning: Got event/censoring at start time. Should be removed! It is set s.t. it has no contribution to loss.\n",
      "  warnings.warn(\"\"\"Got event/censoring at start time. Should be removed! It is set s.t. it has no contribution to loss.\"\"\")\n",
      "/archive/home/gbirolo/projects/als-surv-benchmarks/./SurvTRACE/survtrace/train_utils.py:208: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1420.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    }
   ],
   "source": [
    "out = sys.stdout\n",
    "if args.trials is None:\n",
    "    selected_methods = method_lists['ALL']\n",
    "    max_trials = [0]\n",
    "else:\n",
    "    selected_methods = method_lists[detected_device if args.models == 'AUTO' else args.models]\n",
    "    max_trials = args.trials\n",
    "for trials in max_trials:\n",
    "    print('Required trials:', trials, file=out)\n",
    "    eacc, tacc = run_par(selected_methods, seeds=args.seeds, trials=trials, skip_eval=args.skip_eval, n_jobs=args.cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4752178-b205-4669-8ff4-fe73f55d47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df = pandas.concat({k: pandas.Series(c, dtype=int) for k, c in tacc.items()}).reset_index()\n",
    "trial_df.columns = ['SEED', 'METHOD', 'MODE', 'EVENT', 'STATE', 'COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153eef1-8553-4132-8a8c-9b5cb4714cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df.query('STATE == \"COMPLETE\"').groupby(['METHOD', 'MODE', 'EVENT', 'STATE', 'COUNT']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4dc3e5-0463-4850-8a38-17caca642b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.skip_eval:\n",
    "    print('ALL DONE')\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff90b6-3c5a-47e6-937e-6708ff5bed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pandas.concat({k: s for k, s in eacc.items() if len(s) > 0}, names=['SEED', 'METHOD', 'MODE', 'EVENT']).unstack('METRIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f83008-a3fe-4801-8fb7-3658837be57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an evaluation for each of 10 seeds\n",
    "assert (eval_df.groupby(['METHOD', 'MODE', 'EVENT', 'TIME']).count() == 10).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54954940-9afa-4632-8ab2-cb63fdb52e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05908db5-a2ac-49f7-9653-721a22c64b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv('eval_df_cache.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8f01c-0eeb-4cce-8b71-ed0ffa9b258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pandas.read_csv('eval_df_cache.csv', index_col=['SEED', 'METHOD', 'MODE', 'EVENT', 'ITIME', 'TIME'])\n",
    "eval_df.columns.name = 'METRIC'\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede113a7-2548-4743-8b39-ceee7549ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(score):\n",
    "    return eval_df[score].reset_index().drop(\n",
    "        ['SEED', 'TIME'], axis=1).groupby(['METHOD', 'MODE', 'EVENT']).agg(\n",
    "        ['mean', 'min', 'max', 'count']).sort_values((score, 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8e19bc-d9c5-485b-a89e-531617c1b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.set_style(\"whitegrid\")\n",
    "def plot_score(score):\n",
    "    data = eval_df[score].reset_index()\n",
    "    plot = seaborn.catplot(\n",
    "        data=data,\n",
    "        x='METHOD',\n",
    "        y=score,\n",
    "        hue='MODE',\n",
    "        row='EVENT',\n",
    "        kind='box',\n",
    "        aspect=2,\n",
    "        sharey=False,\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    return plot\n",
    "def plot_score_times(score):\n",
    "    data = eval_df[score].reset_index()\n",
    "    data['METHOD-MODE'] = data['METHOD'] + '\\n' + data['MODE']\n",
    "    plot = seaborn.catplot(\n",
    "        data=data,\n",
    "        x='METHOD-MODE',\n",
    "        y=score,\n",
    "        hue='ITIME',\n",
    "        row='EVENT',\n",
    "        kind='box',\n",
    "        aspect=2,\n",
    "        sharey=False,\n",
    "    )\n",
    "    plt.xticks(rotation=90)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac7dbb-eb37-4fe3-a6c7-ef460dfd64b9",
   "metadata": {},
   "source": [
    "### concordance_index_censored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c5ecb-ca66-4338-8a48-f071475e2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score('concordance_index_censored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869eb6cf-0cad-4fee-bbdb-e78e1d3fbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_times('concordance_index_censored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c833987-b16a-41bd-9070-abef6c64f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score('concordance_index_censored')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28213bdc-1924-468d-8901-de676864f1ee",
   "metadata": {},
   "source": [
    "### concordance_index_ipcw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d480481-2010-469d-8c2b-e1cc2c9d9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score('concordance_index_ipcw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c90c43-1064-4399-bfe3-932567d75a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_times('concordance_index_ipcw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c087f9-5044-419b-aacf-9e033f37cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score('concordance_index_ipcw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6528dc-a2e3-4f8f-9a58-63edf0edcd6e",
   "metadata": {},
   "source": [
    "### cumulative_dynamic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eaee24-543c-4966-b19f-7e96b2b9521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score('cumulative_dynamic_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7780e-2cb3-4c59-8a92-fdf2bd7d3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_times('cumulative_dynamic_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5501f6-2b24-43f5-9f32-f3aaafe91e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score('cumulative_dynamic_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f5ba2-4026-4380-8347-021dbf00eda0",
   "metadata": {},
   "source": [
    "### raw_brier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200fb373-020b-4c5f-917d-89bec044d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score('raw_brier_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c70bfa-fa05-49aa-b53c-326ea1550cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_score_times('raw_brier_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24a59a-e2a1-4a5e-864b-b9602055e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score('raw_brier_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d56f4-4acc-4ec2-a5e9-e6758ce48789",
   "metadata": {},
   "source": [
    "## best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c8213-b1e3-477f-8be7-eba7b3ec2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "outtype = 'independent'\n",
    "evt = 'death'\n",
    "method = GBM\n",
    "acc = {}\n",
    "for seed in range(10):\n",
    "    study_name = f'{method.short_name}_diag_{outtype}_{evt}_{seed}'\n",
    "    study = optuna.create_study(\n",
    "        direction='maximize', \n",
    "        sampler=optuna.samplers.RandomSampler(seed=seed), \n",
    "        study_name=study_name, \n",
    "        load_if_exists=True,\n",
    "        storage=f'sqlite:///{work_dir}/{study_name}.optuna.sqlite3',\n",
    "    )\n",
    "    acc[seed] = study.trials_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693651e6-6cae-4879-b281-a6d6084a93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.concat(acc, names=['seed', 'trial']).reset_index()\n",
    "param_cols = {c: c[7:] for c in df.columns if c.startswith('params_')}\n",
    "df = df.rename(columns=param_cols).rename(columns={'value': 'c-index'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb33fb-7fae-4bf7-b21d-27397086d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c-index'].plot.hist()\n",
    "#df[plot_cols.keys()].rename(columns=plot_cols).sort_values('c-index', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd59434-7fad-4ed1-a1d0-bc918b0b0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_cols.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40017cab-d76b-4537-941d-73e48752f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c-index-interval'] = pandas.qcut(df['c-index'], [0.0, 0.5, 0.75, 0.9, 1.0]).astype(str)\n",
    "lf = df.set_index('c-index-interval')[param_cols.values()].stack().reset_index()\n",
    "lf.columns = 'c-index-interval', 'param', 'value'\n",
    "lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681d5d5-abf8-4950-8b91-e26544a9420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['c-index-interval', p]].value_counts().unstack(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece6e509-cdef-408e-91df-578011215443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f046c-ce11-4cf9-89a2-2cc2e0fcddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_order = sorted(df['c-index-interval'].unique())\n",
    "for p in param_cols.values():\n",
    "    try:\n",
    "        seaborn.boxplot(data=df, x='c-index-interval', y=p, order=int_order)\n",
    "    except TypeError:\n",
    "        m = df[['c-index-interval', p]].value_counts().unstack(p).loc[int_order]\n",
    "        seaborn.heatmap(m, annot=True, fmt='d')\n",
    "    plt.title(p)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3941c-c30a-449a-ab1f-93bed2612e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.catplot(data=lf, x='c-index-interval', y='value', col='param', sharey=False, col_wrap=4, kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b74e4a-b37d-49ee-9583-4928ce9119f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15, 7))\n",
    "optuna.visualization.matplotlib.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a15a9-ad49-457a-852a-926bfb5bbc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac16a4-3d5e-4aee-93ba-9636a1622030",
   "metadata": {},
   "outputs": [],
   "source": [
    "    study = optuna.create_study(\n",
    "        direction='maximize', sampler=optuna.samplers.RandomSampler(seed=seed), study_name=study_name, load_if_exists=True,\n",
    "        storage=(f'sqlite:///{work_dir}/{study_name}.optuna.sqlite3' if study_name is not None else None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c385928-5d23-4c2f-8cee-b94c5c51f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if script:\n",
    "    print('ALL DONE')\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16416c14-49bc-4006-af84-f8b9898b2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, 'STOP HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3444c65-9f6c-471d-ae46-bef409fd852c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e8b4b-3ca0-4203-bd8b-68152b44dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    Xdev, time_dev, event_dev = test_data\n",
    "    from sksurv.nonparametric import ipc_weights\n",
    "    evt = 0\n",
    "    return ipc_weights(event_dev[:, evt], time_dev[:, evt])\n",
    "#seaborn.displot(f())\n",
    "numpy.sort(f())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09be7a7-c430-4e4d-91bc-ce40322b4be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    Xdev, time_dev, event_dev = test_data\n",
    "    preds = m.predict(Xdev, eval_times_dev)\n",
    "    t= 36\n",
    "    raw = [[sf(t) for sf in m.predict_survival_function(Xdev)] for m in m.models_]\n",
    "    #sf = m.models_[0].predict_cumulative_hazard_function(Xdev)[1]\n",
    "    raw = [[1 - sf(t) for sf in m.predict_survival_function(Xdev)] for m in m.models_]\n",
    "    return raw\n",
    "    #numpy.mean(numpy.square(preds[:, evt]\n",
    "    for evt in range(time_dev.shape[1]):\n",
    "        for ti, t in enumerate(eval_times_dev[evt]):\n",
    "            keep = (time_dev[:, evt] > t) | event_dev[:, evt]\n",
    "            #print(numpy.mean(keep))\n",
    "            p = preds[keep, evt, ti]\n",
    "            y = time_dev[keep] > t\n",
    "            score = numpy.mean(numpy.square(p - y))\n",
    "            break\n",
    "    return score\n",
    "max(f()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b871b3-c224-4935-a606-2e406be44940",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.models_[0].predict_cumulative_hazard_function(Xtmp)[2](2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178a8f3-09b0-459d-b38e-e3bc0d495a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.array([[[sf(t) for t in [3,7, 12, 18, 36]] for sf in mm.predict_cumulative_hazard_function(Xtmp)] for mm in m.models_]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9001ccc-1247-4fb1-a3c0-9a608d8a8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.array([[numpy.interp([3,7, 18], sf.x, sf.y) for sf in mm.predict_cumulative_hazard_function(Xtmp)] for mm in m.models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39af4c-42ea-437a-8439-5e3819718f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = m.models_[0].predict_cumulative_hazard_function(Xtmp)#[0].y.shape\n",
    "[numpy.interp([3,7], sf.x, sf.y) for sf in m.models_[0].predict_cumulative_hazard_function(Xtmp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d139a-688d-4b34-be3f-367f0aa033fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b2007-83eb-43bf-83a8-30ac45427c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SkCoxPH(study.best_trial).predict(Xdiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a44769-da6a-42bb-8b9c-37984291d1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d23ac3-3e43-4f14-ab04-db1884e6d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc, concordance_index_censored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20108176-7293-4f6d-8959-1143d409b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k, v in globals().items() if k[0] != '_' and type(v) != type(numpy)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
